

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Why use wavelets in music information retrieval? &#8212; Kymatio: Deep Learning meets Wavelet Theory for Music Signal Processing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ch1_intro/why_wavelets';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Introduction to Wavelets" href="../ch2_wavelets/intro.html" />
    <link rel="prev" title="Tutorial Scope" href="tutorial_scope.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://avatars.githubusercontent.com/u/45135504?s=400&u=1aaba37c0e94a44c7aef727151b071278f3e4f3b&v=4" class="logo__image only-light" alt="Kymatio: Deep Learning meets Wavelet Theory for Music Signal Processing - Home"/>
    <script>document.write(`<img src="https://avatars.githubusercontent.com/u/45135504?s=400&u=1aaba37c0e94a44c7aef727151b071278f3e4f3b&v=4" class="logo__image only-dark" alt="Kymatio: Deep Learning meets Wavelet Theory for Music Signal Processing - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Kymatio: Deep Learning meets Wavelet Theory for Music Signal Processing
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="tutorial_structure.html">Tutorial Structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_scope.html">Tutorial Scope</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Why use wavelets in music information retrieval?</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics of wavelets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch2_wavelets/intro.html">Introduction to Wavelets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch2_wavelets/morlet1d.html">1D Morlet Wavelets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch2_wavelets/filterbanks.html">Wavelet Filterbanks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch2_wavelets/morlet2d.html">2D Morlet Wavelets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch2_wavelets/1_wavelets.html">Notebook 1 - Introduction to Wavelets</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Scattering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/wavelet_transform.html">Intro to Wavelet Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/wavelet_fbank.html">Wavelet Filterbanks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/order1.html">First-order Scattering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/scalogram.html">Wavelet Scalogram</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/order2.html">Second-order Scattering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/jtfs.html">Time-Frequency Scattering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch3_scattering/2_scattering.html">Notebook 2 - Scattering Transforms with Kymatio</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Scattering in MIR</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/task.html">Musical Playing Technique Classification with Hybrid Scattering ConvNets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/dataset.html">SOL Playing Techniques Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/convnet.html">Convnet Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/eval.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/extensions.html">Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch4_mir/3_ipt_classification.html">Notebook 3 - Musical Playing Technique Classification</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">GEAR: Generative Evaluation of Audio Representations</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch5_gear/gear.html">GEAR: Generative Evaluation of Audio Representations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch5_gear/amfm_synth.html">AM/FM Chirp Dataset Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch5_gear/eval.html">Generative Evaluation of Audio Representations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch5_gear/knn.html">Nearest Neighbors Regression of Synth Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch5_gear/4_gear.html">Notebook 4 - GEAR: Generative Evaluation of Audio Representations</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Differentiable Time-Frequency Analysis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/dtfa.html">DTFA: Differentiable Time-Frequency Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/ddsp.html">Differentiable digital signal processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/jtfs_loss.html">Time-Frequency Scattering Distance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/chirplet_arp.html">Differentiable Chirplet Arpeggiator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/micro_to_meso.html">From the microscale to the mesoscale</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/gradient_viz.html">Parameter Estimation by Gradient Descent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch6_dtfa/5_dtfa.html">Notebook 5 - DTFA: Differentiable Time-Frequency Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ch7_resources/references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch7_resources/acknowledgements.html">Acknowledgements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ch7_resources/authors.html">Authors</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/kymatio/ismir23-tutorial" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/kymatio/ismir23-tutorial/issues/new?title=Issue%20on%20page%20%2Fch1_intro/why_wavelets.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/ch1_intro/why_wavelets.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Why use wavelets in music information retrieval?</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-learning-with-limited-labeled-data">1. For learning with limited labeled data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-physical-interpretability">2. For physical interpretability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-biological-plausibility">3. For biological plausibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-artistic-creation">4. For artistic creation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-mathematical-understanding">5. For mathematical understanding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="why-use-wavelets-in-music-information-retrieval">
<h1>Why use wavelets in music information retrieval?<a class="headerlink" href="#why-use-wavelets-in-music-information-retrieval" title="Permalink to this heading">#</a></h1>
<p>The modern theory of wavelets dates back to the 1980s, with wide industrial applications as soon as the 1990s.
In comparison, the renewed interest for deep learning is more recent: around the year 2012 in speech and image processing and at ISMIR a few years later.
Today, some of the most foundational elements of the standard MIR toolkit may involve wavelets, with CQT and chroma features being noteworthy examples.
However, these tools are no longer considered as original contributions.
Instead, current publications tend to take them for granted and apply them as preprocessing blocks to a deep neural network architecture.</p>
<p>As members of the Kymatio consortium, we recognize the value of end-to-end learning in its applications to music signal processing.
Long-standing MIR tasks such as automatic chord estimation and downbeat tracking have undoubtedly made great progress since the replacement of feature engineering by feature learning.
At the same time, the past decade has shown that wavelets are still relevant in scientific research; not so much in their own right but by producing fruitful interactions with machine learning models.
In this section, we outline five such modes of interaction:</p>
<ol class="arabic simple">
<li><p>Learning with limited labeled data</p></li>
<li><p>Physical interpretability</p></li>
<li><p>Biological plausbility</p></li>
<li><p>Artistic creation</p></li>
<li><p>Mathematical understanding</p></li>
</ol>
<section id="for-learning-with-limited-labeled-data">
<h2>1. For learning with limited labeled data<a class="headerlink" href="#for-learning-with-limited-labeled-data" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>Under a supervised regime, deep neural networks require a large amount of labeled data to produce generalizable representations of audio.
Since the annotation of music is a tedious process, the adoption of deep learning in MIR is costly and time-consuming.
This is particularly true in under-appreciated areas of MIR, such as non-Western corpora and expert taxonomies for digital humanities.
Certainly, recent advances in self-supervised learning (SSL) have opened the possibility of developing application-agnostic, “foundation” models from large amounts of unlabeled data.
However, the current state of the art in SSL for audio processing is unable to transfer to fine-grained applications; e.g., the classification of instrumental playing techniques (IPT), as we will see in chapter 3.
Furthermore, SSL models which rely on audiovisual correspoondence, such as Open-L3, lack a “common-sensical” understanding of musical acoustics, in the sense that they misrepresent variations in fundamental frequency or tempo [1].
Chapter 4 will evaluate the abilities of Open-L3 for unsupervised learning of the factors of variability underlying a synthetic data, and show that these abilities remain below those of scattering transforms, a wavelet-based representation which requires no pre-training stage.</p>
</section>
<section id="for-physical-interpretability">
<h2>2. For physical interpretability<a class="headerlink" href="#for-physical-interpretability" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>A well-known shortcoming of deep neural networks is that their activations are difficult to interpret beyond the first layer.
Although this is not necessarily a concern for MIR products, it does hamper the ability of neural networks to advance scientific knowledge in musical acoustics and digital humanities.
Meanwhile, wavelet coefficients are linked to precise physical quantities, such as time scale, center frequency, bandwidth, and energy.
The same is true of scattering transforms, in which the first-order wavelets relate to carrier frequencies whereas second-order wavelets relate to modulation frequencies.
Chapters 2 and 3 will explain how to construct filterbanks for wavelet transforms and scattering transforms respectively.
Then, Chapter 4 will show how a scattering transform may be interfaced with a deep convolutional network so as to perform audio classification of playing techniques such as tremolo and vibrato.
With a gradient-based method known as layerwise relevance propagation (LRP), we will visualize which coefficient is most informative to the classifier for any given audio input [2].
Hence, this kind of hybrid architecture offers insight on the physical underpinnings of musical playing techniques: for example, the scattering coefficient which are associated to the vibrato rate stands out as a more relevant feature than those associated to the spectral envelope.
This is consistent with our understanding of sound production and could not have been achieved with a spectrogram-based neural network.</p>
</section>
<section id="for-biological-plausibility">
<h2>3. For biological plausibility<a class="headerlink" href="#for-biological-plausibility" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>The computational architecture of deep neural networks bear a structural resemblance with the biological cortex.
However, this resemblance is too elusive to draw precise connections between machine learning and cognitive science.
In particular, typical MIR systems are inadequate models of the auditory cortex, even so their output responses may correctly predict the ground truth.
The situation is different with the joint time–frequency scattering transform (JTFS), a deep convolutional operator which is derived from wavelet theory and incurs no learning stage.
Prior work on auditory neurophysiology has shown that in mammalians, the early stages auditory cortex operates with localized spectrotemporal receptive fields (STRF), which resemble two-dimensional wavelets in the time–frequency domain.
These findings suggest that JTFS appears as a biologically plausible model of timbre, defined as the low-level cognitive features underlying musical cognition [3].
A recent publication has confirmed the usefulness of JTFS in timbre perception research by showing that Euclidean distances between JTFS coefficients predict judgments of timbre dissimilarity between isolated musical notes involving extended playing techniques [4].
Chapter 3 will present the theory and implementation of JTFS in Kymatio, while chapter 5 while derive an application to the timbral exploration of an AM/FM synthesizer.</p>
</section>
<section id="for-artistic-creation">
<h2>4. For artistic creation<a class="headerlink" href="#for-artistic-creation" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>There is a growing interest for connectionist architectures and iterative refinement in contemporary music creation.
In particular, artificial neural networks have been used for digital audio synthesis since at least the 1980s.
However, for aesthetic reasons, certain artist prefer to generate sounds with wavelets and joint time–frequency scattering (JTFS) rather than with pretrained neural networks.
One such aesthetic reason is that JTFS offers an idealized simulation of auditory perception yet without any exposure to real-world data: as such, it can regarded as a “blank slate” mathematical model for machine perception.
Furthermore, since JTFS is differentiable, it is amenable to numerical transformation and waveform resynthesis by gradient descent.
Since 2016, composer Florian Hecker has worked with the Kymatio consortium to produce music under different formats, including:</p>
<ul class="simple">
<li><p>concerts at Alte Oper (Frankfurt)</p></li>
<li><p>installation at the “Geometry of Now” gallery (Moscow)</p></li>
<li><p>concerts at the Underground Film Festival (Lausanne)</p></li>
<li><p>multimedia installations at the Kunsthalle (Vienna)</p></li>
<li><p>radio broadcast from BBC Maida Vale studios (London)</p></li>
<li><p>stereocassette for Editions Mego (Vienna)</p></li>
<li><p>illustrated book for Sternberg Press (Berlin)</p></li>
<li><p>CD release for Urbanomic (London)</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=e3VJ-I5Wxl4">vinyl release</a> for Warp Records (London)
These creations illustrate the creative potential of JTFS for digital audio effects [5].
In Chapter 6, we will elaborate on these findings to show that JTFS can serve in differentiable digital signal processing (DDSP) for perceptually driven transformations of music signals [6].</p></li>
</ul>
</section>
<section id="for-mathematical-understanding">
<h2>5. For mathematical understanding<a class="headerlink" href="#for-mathematical-understanding" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<p>The mathematical foundations of deep learning remains in infancy [7].
Meanwhile, our understanding of wavelets has considerably advanced over the past thirty years: we now have clear guidelines for wavelet design, approximation theorems for coding and compression, and fast resursive implementations [8].
Similarly, the development of scattering transforms was partially motivated by an algebraic theory of invariance and stability to signal deformations [9].
The development of joint time-frequency scattering has extended this theory to convolutional operators over the time–frequency domain and has strengthened the thematic link between scattering transforms and deep neural networks [10].
In this context, gaining familiarity with Kymatio can serve as a preparation step for advancing knowledge on neural networks and come up with innovative ideas.
At ISMIR 2023, one example is found in PESTO, a deep neural network for pitch estimation in which learnable Toeplitz matrices induce a self-supervised transposition-equivariant objective [11].
Although PESTO does not directly rely on wavelet theory to address its MIR application, it shares a common inspiration with scattering transforms because of its systematic treatment of equivariance to factors of variability in the time–frequency domain: see Chapter 4 in particular.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<hr class="docutils" />
<ol class="arabic simple">
<li><p><a class="reference external" href="https://hal.science/hal-03979667/">“From HEAR to GEAR: Generative Evaluation of Audio Representations” by Vincent Lostanlen, Lingyao Yan, and Xianyi Yang</a></p></li>
<li><p><a class="reference external" href="https://hal.science/hal-04029145/">“Explainable Audio Classification of Playing Techniques with Layer-wise Relevance Propagation” by Changhong Wang, Vincent Lostanlen, and Mathieu Lagrange</a></p></li>
<li><p><a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002759">“Music in Our Ears: The Biological Bases of Musical Timbre Perception” by Kailash Patil, Daniel Pressnitzer, Shihab Shamma, and Mounya Elhilali</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2007.10926">“Time–frequency scattering accurately models auditory similarities between instrumental playing techniques” by Vincent Lostanlen, Christian El-Hajj, Mathias Rossignol, Grégoire Lafay, Joakim Andén and Mathieu Lagrange</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.09334">“The Shape of RemiXXXes to Come: Audio texture synthesis with time-frequency scattering” by Vincent Lostanlen and Florian Hecker</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2301.10183">“Mesostructures: Beyond Spectrogram Loss in Differentiable Time-Frequency Analysis” by Cyrus Vahidi, Han Han, Changhong Wang, Mathieu Lagrange, György Fazekas, and Vincent Lostanlen</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1601.04920">“Understanding Deep Convolutional Networks” by Stéphane Mallat</a></p></li>
<li><p><a class="reference external" href="https://www.fourierandwavelets.org/FWSP_a3.2_2013.pdf">“Fourier and Wavelet Signal Processing” by Jelena Kovacevic, Vivek K. Goyal, and Martin Vetterli</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/absf/1101.2286">“Group Invariant Scattering” by Stéphane Mallat</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1807.08869">“Joint time–frequency scattering” by Joakim Andén, Vincent Lostanlen, and Stéphane Mallat</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2309.02265">“PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective” by Alain Riou, Stefan Lattner, Gaëtan Hadjeres, Geoffroy Peeters</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./ch1_intro"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="tutorial_scope.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tutorial Scope</p>
      </div>
    </a>
    <a class="right-next"
       href="../ch2_wavelets/intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Introduction to Wavelets</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-learning-with-limited-labeled-data">1. For learning with limited labeled data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-physical-interpretability">2. For physical interpretability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-biological-plausibility">3. For biological plausibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-artistic-creation">4. For artistic creation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#for-mathematical-understanding">5. For mathematical understanding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cyrus Vahidi, Christopher Mitcheltree, Vincent Lostanlen
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>